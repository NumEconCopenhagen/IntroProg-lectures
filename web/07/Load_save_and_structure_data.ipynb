{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 07: Load/save and structure data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53382c54",
   "metadata": {},
   "source": [
    "[Download on GitHub](https://github.com/NumEconCopenhagen/lectures-2022)\n",
    "\n",
    "[<img src=\"https://mybinder.org/badge_logo.svg\">](https://mybinder.org/v2/gh/NumEconCopenhagen/lectures-2022/master?urlpath=lab/tree/07/Load_save_and_structure_data.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f01608",
   "metadata": {},
   "source": [
    "1. [Pandas dataframes](#Pandas-dataframes)\n",
    "2. [Reading and writing data](#Reading-and-writing-data)\n",
    "3. [Summary](#Summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first take a quick survey on the Inaugural assignment process, found [here](https://forms.office.com/Pages/ResponsePage.aspx?id=kX-So6HNlkaviYyfHO_6kckJrnVYqJlJgGf8Jm3FvY9UMEZTODYyVjJWSFBPNTVRMzBMQzFYOE5JQiQlQCN0PWcu)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will learn to **load and save data** both to and from offline sources (e.g. CSV or Excel). You will learn about **pandas series and dataframes**, and how to clean, rename, structure and index your data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Links:**\n",
    "\n",
    "1. Official [tutorials](https://pandas.pydata.org/pandas-docs/stable/getting_started/tutorials.html)\n",
    "2. DataCamp's [pandas' cheat sheet](https://www.datacamp.com/community/blog/python-pandas-cheat-sheet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Pandas-dataframes\"></a>\n",
    "\n",
    "# 1. Pandas dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Pandas, the fundamental object of interest is a **pandas dataframe**. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(data = [[1,11.7,'Vitus'],[2,13.9,'Maximilian'],[3,14.6,'Bo-Bob']], \n",
    "                 columns=['id','inc','name'])\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A dataframe is essentially a matrix.**\n",
    "\n",
    "* rows = observations \n",
    "* columns = variables "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**General information:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What does `object` mean?** In practice it is a `str`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** You can also show a dataframe in the  middle of some code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('before')\n",
    "display(X)\n",
    "print('after')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Indexing (\"subsetting\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Choosing a subset of the rows and/or columns of a dataframe is known as \"indexing\"**. \n",
    "\n",
    "Recall the stuff about ***slicing*** and ***logical indices*** from previous lectures. Since Pandas is build in Numpy, we can do the same here.\n",
    "\n",
    "All pandas dataframes are born with the method `.loc[]` and `.iloc[]`. `.iloc[]` is for numeric indexing and `.loc[]` for logical and name-based indexing. \n",
    "\n",
    "* `df.loc[:, ['year']]` selects all rows (indicated by `:`) but only the column (variable) `year`. \n",
    "* `df.loc[df['year'] == 2002, :]` selects the rows where the variable `year` is equal to 2002 and all columns (indicated by `:`)\n",
    "* `df.loc[df['year'] == 2002, ['name']]` selects the variable `name` and shows the rows where `year` is equal to 2002. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, the **syntax** is `df.loc[CONDITION, [VARLIST]]`, where `CONDITION` is a vector of logical statements with the same length as the number of rows in the dataframe, and `VARLIST` is a list over variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.loc[X['id'] > 1, ['name']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.loc[X['id'] > 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Alternatives:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a boolean series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I = X['id'] > 1\n",
    "print(I)\n",
    "X.loc[I, ['name']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `.VARIABLE` notation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.loc[(X.id > 1) & (X.inc > 14), ['id','name']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why do you think the `.VARIABLE` notation works at all? What does it make you suspect a variable is to the DataFrame?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\"> **WARNING!**</span> you can in fact subset with a numeric index by `.loc`. **But** then we are **not** in half-open intervals. We are in **closed intervals**. So for your own sake, *never* do that. Use `.iloc` for numeric index. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subsetting with numerical indexing works the same way as lists and arrays.  \n",
    "**Syntax:** `df.iloc[ROW INDICES, [COLUMN INDICES]]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(X.iloc[0:2,[0,2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember the **half-open** intervals!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Adding a variable\n",
    "\n",
    "Variables are added with `df['newvar'] = SOMETHING`. The length must match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['year'] = [2003, 2005, 2010]\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** You canNOT write `df.newvar = SOMETHING`. Some of you will forget. I promise.  \n",
    "**Also:** note that you could add the year-variable even though it does not have an explicit row dimension. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *something* can be an **expression based on other variables**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['inc_adj'] = X.inc / 1.02**(X.year-2005)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Assignments to a subset of rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LHS:** Selected using logical statement.<br>\n",
    "**RHS:** Must either be:\n",
    "\n",
    "1. a **single value** (all rows are set to this) \n",
    "2. a **list of values** with same length as the number of selected rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Multiple rows, one value:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create copy of X to avoid overwriting it.\n",
    "Y = X.iloc[:,0:4].copy()\n",
    "Y.loc[Y.id > 1, ['name']] = 'no name'\n",
    "print('Y After change in names:')\n",
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Multiple rows, multiple values:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Original df:')\n",
    "Y = X.iloc[:,0:4].copy()\n",
    "display(Y)\n",
    "\n",
    "# Subset the rows, where name is Vitus or year is 2005. LHS is incidentally only 2 rows, which match the RHS!\n",
    "I = (Y.name == 'Vitus') | (Y.year == 2010)\n",
    "\n",
    "# Print LHS\n",
    "print('Subset of Y, LHS in assignment:')\n",
    "display(Y.loc[I,:])\n",
    "\n",
    "# Assignment\n",
    "Y.loc[I, ['name']] = ['Bib', 'Peter']\n",
    "\n",
    "print('Final Y:')\n",
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Copies vs. views"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember the stuff about references to objects from L02 and how making changes in a reference also causes changes in the \"original\" object? Pandas sort of shields you from that trap.  \n",
    "Here is how:\n",
    "When **looking** at the data it is natural to just avoid the `.loc` (as in most other languages):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here I'm NOT using the .loc function\n",
    "Z = Y[['id','name']]\n",
    "Z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can even make subsets without it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I = Y['id'] > 1\n",
    "Z[I]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importantly, this **does not work with assignment**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Case 1:** Sometimes it does not work outright."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(X)\n",
    "Y = X.copy() # Create Y as a new instance by copying\n",
    "Z1 = Y[['id','name']] # returns a view through chained assignment\n",
    "Z2 = Y.loc[:, ['id','name']] \n",
    "I = Y['id'] > 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We canNot change Z1 due to the assignment method\n",
    "Z1.loc[I, ['name']] = 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# But it works with Z2 \n",
    "Z2.loc[I, ['name']] = 'test'\n",
    "display(Y) # However, we did not change names in Y\n",
    "display(Z2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Case 2:** Sometimes it works, but it is not intended use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display(X)\n",
    "Y = X.copy()\n",
    "\n",
    "I = Y['id'] > 1\n",
    "Z = Y['name'] # returns a view of the column (same with Y.name)\n",
    "Z[I] = 'test' # Reassigning values to the view of name in Y\n",
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:** Do the assignment in one step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I = Y['id'] > 1\n",
    "Y.loc[I, ['name']] = 'test'\n",
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets have a [**quizz**](https://forms.office.com/Pages/ResponsePage.aspx?id=kX-So6HNlkaviYyfHO_6kckJrnVYqJlJgGf8Jm3FvY9UNDdSQTgzRU1XMlc3MzJEQUo5UjNCRURDSCQlQCN0PWcu) on subsetting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 The index\n",
    "\n",
    "The **first column** in the dataset is referred to as the `index` of the dataframe.<br>\n",
    "**Baseline:** If you haven't done anything, it is just `[0, 1, 2, ....]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.loc[0]\n",
    "# See the indices of X\n",
    "print(X.index.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Custom:** You can actually use any **unique** identifier. It does not have to be numbers. For example, you can assign the name column to be the index instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = X.set_index('name') # returns a copy\n",
    "Y # notice name is now below the other variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y.loc['Vitus']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See the indices of Y\n",
    "print(Y.index.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 Series and numpy arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you select an individual variable, it has the data type `Series`. Some functions work on a pandas series (e.g. most numpy functions), but it is sometimes nice to extract the underlying numpy objects: \n",
    "\n",
    "* `df`: **pandas dataframe** \n",
    "* `df['variable']`: **pandas series**\n",
    "* `df['variabe'].values` (or `.to_numpy()`): **numpy array**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A subset of a DataFrame is a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(X[['year','inc_adj']]) # returns a copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(X['year']) # returns a view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([*X['year'].values]) # returns a view"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** A pd.Series can live outside a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = [0.1,0.2,1.3]\n",
    "s = pd.Series(d)\n",
    "print(s, type(s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.7 Calling functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Row-by-row** Create function that takes row as an argument, and then **apply** the action of the function along the row dimension (axis=1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = X.copy()\n",
    "\n",
    "# Notice that row is an input argument here\n",
    "def conc_row_wise(row):\n",
    "    return str(row['year']) + ' - ' + row['name'] \n",
    "\n",
    "# The fact that row is an input argument in the conc_row_wise function is implicitly understood by .apply()\n",
    "Y['year_name'] = Y.apply(conc_row_wise, axis=1) # Notice that axis = 1 is going down rows. Kind of confusing. \n",
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Function for numpy arrays:** use the fact that a Pandas df is based on Numpy arrays to create a function that operate on the rows. This may involve broadcasting (see L03). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_at_once(inc, year):\n",
    "    return inc*year.max() # Notice that the values of a pd DataFrame column is Numpy, so it has a .max() method. \n",
    "\n",
    "Y['inc_adj_year'] = all_at_once(Y.inc.values, Y.year.values)\n",
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Function for numpy arrays with inplace changes** (i.e. a function without any return statement):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use referencing of a column to overwrite values in place.\n",
    "def all_at_once_inplace(inc,year):\n",
    "    inc[:] = all_at_once(inc,year)\n",
    "\n",
    "Y['inc_adj_inplace'] = Y.inc\n",
    "all_at_once_inplace(Y.inc_adj_inplace.values, Y.year.values)\n",
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Reading-and-writing-data\"></a>\n",
    "\n",
    "# 2. Reading and writing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check:** We make sure that we have the **data/** subfolder, and that it has the datasets we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "# Using assert to check that paths exist on computer. See L05 for details.\n",
    "assert os.path.isdir('data/')\n",
    "assert os.path.isfile('data/RAS200.xlsx')\n",
    "assert os.path.isfile('data/INDKP107.xlsx')\n",
    "\n",
    "# Print everything in data\n",
    "os.listdir('data/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Reading in data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas offers a lot of facilities for **reading and writing to different formats**. The functions have logical names: \n",
    "\n",
    "* CSV: `pd.read_csv()`\n",
    "* SAS: `pd.read_sas()`\n",
    "* Excel: `pd.read_excel()`\n",
    "* Stata: `pd.read_stata()`\n",
    "* Parquet: `pd.read_parquet()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inspecting:** \n",
    "\n",
    "* `df.head(10)` is ued to inspect the first 10 rows\n",
    "* `df.sample(10)` is ued to look at 10 random rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example:** Raw download from DST  \n",
    "\n",
    "Clearly not quite right!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'data/RAS200.xlsx' # open the file and have a look at it\n",
    "pd.read_excel(filename).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to clean this **mess** up."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the right columns and rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Skipping rows:** Clearly, we should **skip** the first three rows and the first four columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empl = pd.read_excel(filename, skiprows=2)\n",
    "empl.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dropping columns:** The first couple of columns are not needed and contain only missing values (denoted by `NaN` (not-a-number)), so we will drop those. \n",
    "\n",
    "**Note:** `df.drop()` is a function that the data frame object applies to itself. Hence, no return value is used.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These columns have to go: 'Unnamed: 0' 'Unnamed: 1' 'Unnamed: 2' 'Unnamed: 3'\n",
    "drop_these = ['Unnamed: ' + str(num) for num in range(4)] # use list comprehension to create list of columns\n",
    "print(drop_these)\n",
    "empl.drop(drop_these, axis=1, inplace=True) # axis = 1 -> columns, inplace=True -> changed, no copy made\n",
    "empl.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Alternative:** Use `del empl['Unnamed: 0'], empl['Unnamed: 1']..`.  \n",
    "\n",
    "**But!** that borders on code repetition.. Would give you 4 places to make code changes rather than 2 as with the list comprehension above, in case data changed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Renaming variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are not happy with the column comprising regions, which is currently called `Unnamed: 4`.   \n",
    "\n",
    "We rename using `df.rename(columns=dict)`, where dict must be a Python *dictionary*. Why a dictionary? It is simply the most practical solution if you are renaming several columns at once. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empl.rename(columns = {'Unnamed: 4':'municipality'}, inplace=True)\n",
    "empl.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Rename all year columns:** We also see that the employment rate in 2008 has been named `2008`. This is allowed in Python, but having a **variable named as a number** can cause **problems** with some functions (and many other programming languages do not even allow it), so let us change their names.   \n",
    "To change all columns, we need to create a dictionary that maps each of the years {2008, ..., 2016} to {e2008, ..., e2016}. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_dict = {}\n",
    "for i in range(2008, 2017+1): # range goes from 2008 to but not including 2018\n",
    "    col_dict[str(i)] = f'e{i}' \n",
    "col_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empl.rename(columns = col_dict, inplace=True)\n",
    "empl.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A big NO-NO!!** is to put *white spaces* in column names. You can theoretically have a column such as empl['e 2017'] in a pandas df, but this is *very likely* to get messy. And you can no longer use `.`notation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extract:** Now we can find the employment rate in the municipality where Christian grew up: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empl.loc[empl.municipality == 'HillerÃ¸d']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping observations that are not actually municipalities \n",
    "\n",
    "The dataset contains observations like \"Region Hovedstaden\", which is not a municipality, so we want to drop such rows. To do this, we can use the `df['var'].str` functionalities. These are all sorts of functions that work with strings, in particular searching for instances of specific content by `df['var'].str.contains('PATTERN')`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build up a logical index I\n",
    "I = empl.municipality.str.contains('Region')\n",
    "I |= empl.municipality.str.contains('Province')\n",
    "I |= empl.municipality.str.contains('All Denmark')\n",
    "empl.loc[I, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Delete these rows:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empl = empl.loc[I == False] # keep everything else\n",
    "empl.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empl.reset_index(inplace = True)\n",
    "empl.loc[0:1,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary statistics \n",
    "\n",
    "To get an overview of employments across municipalities we can use the function `df.describe()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empl.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Single descriptive statistic:** We can also just get the mean for each year:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empl.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Long vs. wide datasets: `pd.wide_to_long()`\n",
    "\n",
    "Often in economic applications, it can be useful to switch between *wide* vs. *long* formats (long is sometimes referred to as *tall*, e.g. in Stata). This is done by the commands `pd.wide_to_long()` (and `pd.long_to_wide()`).  Many types of analysis are easier to do in one format than in another so it is extremely useful to be able to switch comfortably between formats. \n",
    "\n",
    "**Common:** Think of a dataset as having an `ID` and a `PERIOD` variable. In our dataset `empl`, the `ID` variable is `municipality`, and the `PERIOD` variable is `year`. \n",
    "\n",
    "**Wide dataset:** The default from Statistics Denmark: 1 row in data per `ID` and a variable for each `PERIOD`. If there are more than one variable per observation that varies by period, then a new block of period-wise cases must be created along columns.  \n",
    "\n",
    "**Long dataset:** There is one row for each combination of (`ID`, `PERIOD`). Vertical blocks of periods. \n",
    "\n",
    "A **long dataset** is often easier to work with if you have more than one time-varying variable in the data set. \n",
    "\n",
    "In general, Pandas will assume that the variables in the *wide* format have a particular structure: namely they are of the form `XPERIOD`, where `X` is called the \"stub\". In our case, the variable names are e.g. `e2011`, so the stub is `e` and the period (for that variable) is `2011`. You'll want to clean out the variable names if there is anything after the `period` part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empl_long = pd.wide_to_long(empl, stubnames='e', i='municipality', j='year')\n",
    "empl_long.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** The variables `municipality` and `year`  are now in the index!! We see that because they are \"below\" `e` in the `head` overview. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The index variable now consists of tuples. \n",
    "print(empl_long.index.values[0:8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can **select a specific municipality** using ``.xs``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empl_long.xs('Roskilde',level='municipality')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or ``.loc[]`` in a special way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empl_long.loc[empl_long.index.get_level_values('municipality') == 'Roskilde', :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Alternative:** Reset the index, and use `.loc` as normal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empl_long = empl_long.reset_index()\n",
    "empl_long.loc[empl_long.municipality == 'Roskilde', :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting interactively  \n",
    "Here's a cute little plot using the builtin pandas plot function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empl_long.loc[empl_long['municipality'] == 'Roskilde', :].plot(x='year',y='e',legend=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can even do it **interactively**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "def plot_e(df, municipality): \n",
    "    I = df['municipality'] == municipality\n",
    "    ax=df.loc[I,:].plot(x='year', y='e', style='-o', legend=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "widgets.interact(plot_e, \n",
    "    df = widgets.fixed(empl_long),\n",
    "    municipality = widgets.Dropdown(description='Municipality', \n",
    "                                    options=empl_long.municipality.unique(), \n",
    "                                    value='Roskilde')\n",
    "); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Income\n",
    "\n",
    "Next, we will read in the avg. disposable income for highly educated in each municipality. Here we do the cleaning, renaming and structuring in a few condensed lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a. load\n",
    "inc = pd.read_excel('data/INDKP107.xlsx', skiprows=2)\n",
    "\n",
    "# b. clean and rename\n",
    "inc.drop([f'Unnamed: {i}' for i in range(4)], axis=1, inplace=True) # using list comprehension\n",
    "inc.rename(columns = {'Unnamed: 4':'municipality'}, inplace=True) \n",
    "inc.rename(columns = {str(i): f'inc{i}' for i in range(2004,2018)}, inplace=True) # using dictionary comprehension\n",
    "\n",
    "# c. drop rows with missing values. Denoted na\n",
    "inc.dropna(inplace=True)\n",
    "\n",
    "# d. remove non-municipalities. Notice how to avoid code repetition!\n",
    "for val in ['Region','Province', 'All Denmark']: \n",
    "    I = inc.municipality.str.contains(val)\n",
    "    inc.drop(inc[I].index, inplace=True) # .index -> get the indexes of the series\n",
    "    \n",
    "inc.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convert** wide -> long:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inc_long = pd.wide_to_long(df=inc, stubnames='inc', i='municipality', j='year')\n",
    "inc_long.reset_index(inplace=True)\n",
    "inc_long.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Municipal area\n",
    "\n",
    "Finally, let's read in a dataset on municipality areas in km$^2$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a. load\n",
    "area = pd.read_excel('data/areal.xlsx', skiprows=2)\n",
    "\n",
    "# b. clean and rename\n",
    "area.rename(columns = {'Unnamed: 0':'municipality','2019':'km2'}, inplace=True)\n",
    "\n",
    "# c. drop rows with missing\n",
    "area.dropna(inplace=True)\n",
    "\n",
    "# d. remove non-municipalities\n",
    "for val in ['Region','Province', 'All Denmark']: \n",
    "    I = area.municipality.str.contains(val)\n",
    "    area.drop(area[I].index, inplace=True)\n",
    "    \n",
    "area.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Writing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with reading in data, we have the corresponding functions for **writing data**:\n",
    "\n",
    "* CSV: `pd.to_csv()`\n",
    "* SAS: `pd.to_sas()`\n",
    "* Excel: `pd.to_excel()`\n",
    "* Stata: `pd.to_stata()`\n",
    "* Parquet: `pd.to_parquet()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's **save our dataset to CSV form**. We will set `index=False` to avoid saving the index (which does not mean anything here but can in other contexts be an annoying thing). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empl_long.to_csv('data/RAS200_long.csv', index=False)\n",
    "inc_long.to_csv('data/INDKP107_long.csv', index=False)\n",
    "area.to_csv('data/area.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 Be cautious\n",
    "\n",
    "Code for cleaning data tend to get long and repetetive. But remember **DRY**! Errors crop up in data cleaning when you just copy blocks of code around. Avoid repetitions at all costs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Summary\"></a>\n",
    "\n",
    "# 3. Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This lecture**: We have discussed\n",
    "\n",
    "1. The generel pandas framework (indexing, assigment, copies vs. views, functions)\n",
    "2. Loading and saving data\n",
    "3. Basic data cleaning (renaming, droping etc.)\n",
    "4. Wide $\\leftrightarrow$ long transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your work:** Before solving Problem Set 3 read through this notebook and play around with the code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Next lecture:** Basic data analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data exploration?:** Try out [dtale](https://github.com/man-group/dtale)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
